{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reflected-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "import json\n",
    "import string\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import processing as prp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "biblical-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('../Dataset/words_alpha.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grateful-vienna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370102"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = dat.values[:, 0].tolist()\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "architectural-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': ['4', '@', '/\\\\', 'Д', 'а'],\n",
       " 'B': ['8', '|3', '13', '|}', '|8', '18', '6', 'ß', 'в', 'ь'],\n",
       " 'C': ['<', '{', '[', 'C', '©', '¢', 'с'],\n",
       " 'D': ['|)', '|}', '|]', '|>'],\n",
       " 'E': ['3', '£', '₤', '€', 'е'],\n",
       " 'F': ['7', '|=', 'ph', '|#', '|\"', 'ƒ'],\n",
       " 'G': ['[', '-', '[+', '6', 'C-'],\n",
       " 'H': ['#',\n",
       "  '4',\n",
       "  '|-|',\n",
       "  '[-]',\n",
       "  '{-}',\n",
       "  '}-{',\n",
       "  '}{',\n",
       "  '|=|',\n",
       "  '[=]',\n",
       "  '{=}',\n",
       "  '/-/',\n",
       "  '(-)',\n",
       "  ')-(',\n",
       "  ':-:',\n",
       "  'I+I',\n",
       "  'н'],\n",
       " 'I': ['1', '|', '!', '9'],\n",
       " 'J': ['_|', '_/', '_7', '9', '_)', '_]', '_}'],\n",
       " 'K': ['|<', '1<', 'l<', '|{', 'l{'],\n",
       " 'L': ['|_', '|', '1', ']['],\n",
       " 'M': ['44',\n",
       "  '|\\\\/|',\n",
       "  '^^',\n",
       "  '/\\\\/\\\\',\n",
       "  '/X\\\\',\n",
       "  '[]\\\\/][',\n",
       "  '[]V[]',\n",
       "  '][\\\\//][',\n",
       "  '(V)',\n",
       "  '//.',\n",
       "  '.\\\\',\n",
       "  'N\\\\',\n",
       "  'м'],\n",
       " 'N': ['|\\\\|', '/\\\\/', '/V', '][\\\\][', 'И', 'и', 'п'],\n",
       " 'O': ['0', '()', '[]', '{}', '<>', 'Ø', 'oh', 'Θ', 'о', 'ө'],\n",
       " 'P': ['|o', '|O', '|>', '|*', '|°', '|D', '/o', '[]D', '|7', 'р'],\n",
       " 'Q': ['O_', '9', '(,)', '0', 'kw'],\n",
       " 'R': ['|2', '12', '.-', '|^', 'l2', 'Я', '®'],\n",
       " 'S': ['5', '$', '§'],\n",
       " 'T': ['7', '+', '7`', '`|`', '~|~', '-|-', \"']['\", 'т'],\n",
       " 'U': ['|_|', '\\\\_\\\\', '/_/', '\\\\_/', '(_)', '[_]', '{_}'],\n",
       " 'V': ['\\\\/'],\n",
       " 'W': ['\\\\/\\\\/',\n",
       "  '(/\\\\)',\n",
       "  '\\\\^/',\n",
       "  '|/\\\\|',\n",
       "  '\\\\X/',\n",
       "  'VV',\n",
       "  '\\\\_|_/',\n",
       "  '\\\\//\\\\//',\n",
       "  'Ш',\n",
       "  '2u',\n",
       "  '\\\\V/'],\n",
       " 'X': ['%', '*', '><', '}{', ')(', 'Ж'],\n",
       " 'Y': ['`/', '¥', '\\\\|/', 'Ч', 'у'],\n",
       " 'Z': ['2', '5', '7_', '>_', '(/)', '}']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../Dataset/leet_dictionary.json') as f:\n",
    "    aug_dict = json.load(f) \n",
    "    \n",
    "aug_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abstract-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(w_list, sample_size, change_prob = 0.3):\n",
    "    sp = random.sample(w_list, k = sample_size)\n",
    "    return sp, prp.augment(sp,  aug_dict = aug_dict, min_letter_change = 3, change_prob = change_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "compact-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = prp.sample(word_list, aug_dict = aug_dict, change_prob = 0.3, sample_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "excited-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "reserved-conversion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<start> w i g g l e r <end>', '<start> \\\\ / / \\\\ / / 9 g g l e r <end>')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "prime-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_dict = np.unique(list(string.printable + str(aug_dict.values()))).tolist()\n",
    "#main_dict.remove(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "critical-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "north-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_1, x_2 = sample(word_list, sample_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "herbal-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prp.OneHot(x_1, main_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-concert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
