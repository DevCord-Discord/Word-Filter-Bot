{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reflected-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "import json\n",
    "import string\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "import processing as prp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "biblical-wealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('../Dataset/words_alpha.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "grateful-vienna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370102"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = dat.values[:, 0].tolist()\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "architectural-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': ['4', '@', '/\\\\', 'Д', 'а'],\n",
       " 'B': ['8', '|3', '13', '|}', '|8', '18', '6', 'ß', 'в', 'ь'],\n",
       " 'C': ['<', '{', '[', 'C', '©', '¢', 'с'],\n",
       " 'D': ['|)', '|}', '|]', '|>'],\n",
       " 'E': ['3', '£', '₤', '€', 'е'],\n",
       " 'F': ['7', '|=', 'ph', '|#', '|\"', 'ƒ'],\n",
       " 'G': ['[', '-', '[+', '6', 'C-'],\n",
       " 'H': ['#',\n",
       "  '4',\n",
       "  '|-|',\n",
       "  '[-]',\n",
       "  '{-}',\n",
       "  '}-{',\n",
       "  '}{',\n",
       "  '|=|',\n",
       "  '[=]',\n",
       "  '{=}',\n",
       "  '/-/',\n",
       "  '(-)',\n",
       "  ')-(',\n",
       "  ':-:',\n",
       "  'I+I',\n",
       "  'н'],\n",
       " 'I': ['1', '|', '!', '9'],\n",
       " 'J': ['_|', '_/', '_7', '9', '_)', '_]', '_}'],\n",
       " 'K': ['|<', '1<', 'l<', '|{', 'l{'],\n",
       " 'L': ['|_', '|', '1', ']['],\n",
       " 'M': ['44',\n",
       "  '|\\\\/|',\n",
       "  '^^',\n",
       "  '/\\\\/\\\\',\n",
       "  '/X\\\\',\n",
       "  '[]\\\\/][',\n",
       "  '[]V[]',\n",
       "  '][\\\\//][',\n",
       "  '(V)',\n",
       "  '//.',\n",
       "  '.\\\\',\n",
       "  'N\\\\',\n",
       "  'м'],\n",
       " 'N': ['|\\\\|', '/\\\\/', '/V', '][\\\\][', 'И', 'и', 'п'],\n",
       " 'O': ['0', '()', '[]', '{}', '<>', 'Ø', 'oh', 'Θ', 'о', 'ө'],\n",
       " 'P': ['|o', '|O', '|>', '|*', '|°', '|D', '/o', '[]D', '|7', 'р'],\n",
       " 'Q': ['O_', '9', '(,)', '0', 'kw'],\n",
       " 'R': ['|2', '12', '.-', '|^', 'l2', 'Я', '®'],\n",
       " 'S': ['5', '$', '§'],\n",
       " 'T': ['7', '+', '7`', '`|`', '~|~', '-|-', \"']['\", 'т'],\n",
       " 'U': ['|_|', '\\\\_\\\\', '/_/', '\\\\_/', '(_)', '[_]', '{_}'],\n",
       " 'V': ['\\\\/'],\n",
       " 'W': ['\\\\/\\\\/',\n",
       "  '(/\\\\)',\n",
       "  '\\\\^/',\n",
       "  '|/\\\\|',\n",
       "  '\\\\X/',\n",
       "  'VV',\n",
       "  '\\\\_|_/',\n",
       "  '\\\\//\\\\//',\n",
       "  'Ш',\n",
       "  '2u',\n",
       "  '\\\\V/'],\n",
       " 'X': ['%', '*', '><', '}{', ')(', 'Ж'],\n",
       " 'Y': ['`/', '¥', '\\\\|/', 'Ч', 'у'],\n",
       " 'Z': ['2', '5', '7_', '>_', '(/)', '}']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../Dataset/leet_dictionary.json') as f:\n",
    "    aug_dict = json.load(f) \n",
    "    \n",
    "aug_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abstract-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(w_list, sample_size, change_prob = 0.3):\n",
    "    sp = random.sample(w_list, k = sample_size)\n",
    "    return sp, prp.augment(sp,  aug_dict = aug_dict, min_letter_change = 3, change_prob = change_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "compact-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = prp.sample(word_list, aug_dict = aug_dict, change_prob = 0.3, sample_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "excited-conjunction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> s u b o c e a n <end>\n",
      "<start> 5 u b o c e a n <end>\n"
     ]
    }
   ],
   "source": [
    "print(x[-1])\n",
    "print(y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "reserved-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, tok = prp.tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "referenced-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.fit_on_texts(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "biological-highlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<start>': 1,\n",
       " '<end>': 2,\n",
       " 'e': 3,\n",
       " 'i': 4,\n",
       " 'a': 5,\n",
       " 'o': 6,\n",
       " 'n': 7,\n",
       " 't': 8,\n",
       " 'r': 9,\n",
       " 's': 10,\n",
       " 'l': 11,\n",
       " 'c': 12,\n",
       " 'u': 13,\n",
       " 'd': 14,\n",
       " 'p': 15,\n",
       " 'm': 16,\n",
       " '|': 17,\n",
       " 'h': 18,\n",
       " 'g': 19,\n",
       " 'y': 20,\n",
       " 'b': 21,\n",
       " '/': 22,\n",
       " '\\\\': 23,\n",
       " '[': 24,\n",
       " 'v': 25,\n",
       " ']': 26,\n",
       " 'f': 27,\n",
       " '_': 28,\n",
       " 'k': 29,\n",
       " '1': 30,\n",
       " '-': 31,\n",
       " 'w': 32,\n",
       " ')': 33,\n",
       " '$': 34,\n",
       " '}': 35,\n",
       " '9': 36,\n",
       " 'z': 37,\n",
       " '2': 38,\n",
       " '`': 39,\n",
       " '4': 40,\n",
       " '{': 41,\n",
       " '!': 42,\n",
       " '<': 43,\n",
       " 'x': 44,\n",
       " '7': 45,\n",
       " '3': 46,\n",
       " '5': 47,\n",
       " '>': 48,\n",
       " '€': 49,\n",
       " '(': 50,\n",
       " '§': 51,\n",
       " \"'\": 52,\n",
       " 'е': 53,\n",
       " '+': 54,\n",
       " '₤': 55,\n",
       " '@': 56,\n",
       " 'j': 57,\n",
       " '.': 58,\n",
       " '~': 59,\n",
       " '^': 60,\n",
       " '£': 61,\n",
       " 'и': 62,\n",
       " 'q': 63,\n",
       " 'д': 64,\n",
       " 'а': 65,\n",
       " 'ø': 66,\n",
       " 'п': 67,\n",
       " '8': 68,\n",
       " '®': 69,\n",
       " '6': 70,\n",
       " '#': 71,\n",
       " 'т': 72,\n",
       " '0': 73,\n",
       " '%': 74,\n",
       " 'я': 75,\n",
       " 'о': 76,\n",
       " 'с': 77,\n",
       " '&': 78,\n",
       " 'ө': 79,\n",
       " '=': 80,\n",
       " '¢': 81,\n",
       " '*': 82,\n",
       " 'θ': 83,\n",
       " '\\t': 84,\n",
       " ';': 85,\n",
       " '\\n': 86,\n",
       " 'у': 87,\n",
       " '°': 88,\n",
       " '\\x0c': 89,\n",
       " ':': 90,\n",
       " '?': 91,\n",
       " 'в': 92,\n",
       " 'ß': 93,\n",
       " '\"': 94,\n",
       " '¥': 95,\n",
       " 'р': 96,\n",
       " 'ь': 97,\n",
       " '©': 98,\n",
       " 'ч': 99,\n",
       " 'ж': 100,\n",
       " '\\r': 101,\n",
       " 'ƒ': 102,\n",
       " 'м': 103,\n",
       " ',': 104,\n",
       " 'н': 105,\n",
       " '\\x0b': 106,\n",
       " 'ш': 107}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prime-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_dict = np.unique(list(string.printable + str(aug_dict.values()))).tolist()\n",
    "#main_dict.remove(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "critical-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "north-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_1, x_2 = sample(word_list, sample_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "herbal-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prp.OneHot(x_1, main_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-concert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
